{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298f9664-bff5-42fb-a897-5b9cec4b79b4",
   "metadata": {},
   "source": [
    "# Big Data and Data Mining\n",
    "## Assignment 2: NLP\n",
    "### Done by Abylaikhan Shaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88b2f1cd-5d53-4fa4-915f-552288e36bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d9c89-c628-441d-bee5-4759ae720f92",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcc4be54-a1a1-4b46-9a25-166deab77cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7613, 5)\n",
      "Test shape: (3263, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location  \\\n",
       "0   1     NaN      NaN   \n",
       "1   4     NaN      NaN   \n",
       "2   5     NaN      NaN   \n",
       "3   6     NaN      NaN   \n",
       "4   7     NaN      NaN   \n",
       "\n",
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2428f828-3f76-49c8-a884-59f2e411a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in training data:\n",
      " id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      " id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in training data:\\n\", train_df.isnull().sum())\n",
    "print(\"\\nMissing values in test data:\\n\", test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "525f539c-b30e-436d-bd58-c97f57a5a508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    0.57034\n",
      "1    0.42966\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sns.countplot(data=train_df, x='target')\n",
    "plt.title(\"Target Distribution (0 = Not Disaster, 1 = Disaster)\")\n",
    "plt.show()\n",
    "\n",
    "print(train_df['target'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2931e88d-a60d-4c0e-bbbc-1f935b61b4f1",
   "metadata": {},
   "source": [
    "43% is target group, meaning we have more than enough dissaster tweets for models to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b689a3-2259-4e5c-8734-e7f47d0694e3",
   "metadata": {},
   "source": [
    "## 2. Preprocessing Pipeline\n",
    "For this project, I used a simple and efficient text preprocessing pipeline. The quick_clean() function performs basic cleaning by converting text to lowercase, removing URLs, mentions, hashtags, numbers, and punctuation, and collapsing extra spaces.\n",
    "\n",
    "I opted for this lightweight approach due to technical constraints encountered with more advanced preprocessing tools. Specifically, attempts to use nltk for stemming and lemmatization. There was a constant issue with import numpy being not compatible. However, initially there was no issue, I have run them, and what i found is almost no difference with ntlk steeming and lemmatization or without them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b28b19-31dd-4d77-a3f4-414e02de27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_clean(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs, mentions, hashtags, numbers, punctuation (except spaces)\n",
    "    text = re.sub(r\"http\\S+|www\\S+|@\\w+|#\\w+|\\d+\", \"\", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7217b90e-78c8-4861-a9c2-e448b04e797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"clean_text\"] = train_df[\"text\"].apply(quick_clean)\n",
    "test_df[\"clean_text\"] = test_df[\"text\"].apply(quick_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "072ea71b-2f1d-4649-a208-a1d6b99f825b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
       "      <td>our deeds are the reason of this may allah forgive us all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
       "      <td>all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation orders in California</td>\n",
       "      <td>people receive evacuation orders in california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school</td>\n",
       "      <td>just got sent this photo from ruby as smoke from pours into a school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    text  \\\n",
       "0                                                                  Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all   \n",
       "1                                                                                                 Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected   \n",
       "3                                                                      13,000 people receive #wildfires evacuation orders in California    \n",
       "4                                               Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school    \n",
       "\n",
       "                                                                                                                           clean_text  \n",
       "0                                                                           our deeds are the reason of this may allah forgive us all  \n",
       "1                                                                                               forest fire near la ronge sask canada  \n",
       "2  all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected  \n",
       "3                                                                                      people receive evacuation orders in california  \n",
       "4                                                                just got sent this photo from ruby as smoke from pours into a school  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"text\", \"clean_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d108c4-1d45-43f8-adc5-aa93d2fde21f",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction\n",
    "I'll implement and train models using the following representations:\n",
    "\n",
    "ðŸ”¹ One-Hot Encoding\n",
    "\n",
    "ðŸ”¹ Bag of Words (BoW)\n",
    "\n",
    "ðŸ”¹ TF-IDF\n",
    "\n",
    "ðŸ”¹ Word2Vec (I will opt for another similar)\n",
    "\n",
    "ðŸ”¹ Transformer embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0858842b-7d83-46f3-a1a9-9c585984c412",
   "metadata": {},
   "source": [
    "### 1. One-Hot Encoding\n",
    "I'll use CountVectorizer from sklearn. One-Hot is technically just binary BoW, so I'll use binary=True.\n",
    "\n",
    "### Why I Used Logistic Regression\n",
    "I chose Logistic Regression as the primary classification model across all text representation methods because it is a simple, interpretable, and effective baseline for binary classification tasks like this one. It works well with high-dimensional sparse data, such as that produced by TF-IDF or BoW, and is efficient to train even on large datasets. It also allows for quick experimentation and comparison across different feature extraction techniques without introducing complexity from deep learning architectures. Additionally, using the same model across all representations ensures a fair and consistent performance comparison â€” any differences in model accuracy can be more confidently attributed to the representation method rather than to the classifier itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ccc7bfd-6dcc-4440-8d05-f316ee53f1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       874\n",
      "           1       0.79      0.71      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.79      0.78      0.79      1523\n",
      "weighted avg       0.79      0.80      0.79      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split training data\n",
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(train_df[\"clean_text\"], train_df[\"target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# ONE-HOT ENCODING\n",
    "vectorizer_onehot = CountVectorizer(binary=True)\n",
    "X_train_onehot = vectorizer_onehot.fit_transform(X_train_raw)\n",
    "X_val_onehot = vectorizer_onehot.transform(X_val_raw)\n",
    "\n",
    "# Train logistic regression\n",
    "model_onehot = LogisticRegression(max_iter=1000)\n",
    "model_onehot.fit(X_train_onehot, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_val_onehot = y_val\n",
    "y_pred_onehot = model_onehot.predict(X_val_onehot)\n",
    "print(\"One-Hot Encoding Performance:\\n\", classification_report(y_val, y_pred_onehot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2d7607-4dd3-457e-a65d-eb09b4a3c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I am predicting and saving onehot model\n",
    "X_test_onehot = vectorizer_onehot.transform(test_df[\"clean_text\"])\n",
    "preds_onehot = model_onehot.predict(X_test_onehot)\n",
    "\n",
    "submission_onehot = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': preds_onehot\n",
    "})\n",
    "submission_onehot.to_csv(\"submission_onehot.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185e1bc-e6ca-4567-b6c3-92445e2e9517",
   "metadata": {},
   "source": [
    "### 2. Bag of Words (non-binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dc5437b-dda8-4568-b710-eeb545e43e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       874\n",
      "           1       0.80      0.71      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BAG OF WORDS (BoW)\n",
    "vectorizer_bow = CountVectorizer(binary=False)\n",
    "X_train_bow = vectorizer_bow.fit_transform(X_train_raw)\n",
    "X_val_bow = vectorizer_bow.transform(X_val_raw)\n",
    "\n",
    "model_bow = LogisticRegression(max_iter=1000)\n",
    "model_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "y_val_bow = y_val\n",
    "y_pred_bow = model_bow.predict(X_val_bow)\n",
    "print(\"Bag of Words Performance:\\n\", classification_report(y_val, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4fa48c-8dbb-4df5-a42b-7fd8931a9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = vectorizer_bow.transform(test_df[\"clean_text\"])\n",
    "preds_bow = model_bow.predict(X_test_bow)\n",
    "\n",
    "submission_bow = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': preds_bow\n",
    "})\n",
    "submission_bow.to_csv(\"submission_bow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035a047f-3fb1-405c-b26b-9ab2627914c2",
   "metadata": {},
   "source": [
    "### 3. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ee3fab-ab3b-4b39-9979-ef875df12ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.83       874\n",
      "           1       0.82      0.68      0.74       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.78      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train_raw)\n",
    "X_val_tfidf = vectorizer_tfidf.transform(X_val_raw)\n",
    "\n",
    "model_tfidf = LogisticRegression(max_iter=1000)\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_val_tfidf = y_val\n",
    "y_pred_tfidf = model_tfidf.predict(X_val_tfidf)\n",
    "print(\"TF-IDF Performance:\\n\", classification_report(y_val, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2b2839e-f32b-43c5-af38-3a621bce5d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfidf = vectorizer_tfidf.transform(test_df[\"clean_text\"])\n",
    "preds_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "submission_tfidf = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': preds_tfidf\n",
    "})\n",
    "submission_tfidf.to_csv(\"submission_tfidf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165425ff-a9be-4f82-befd-c3e9b84782c3",
   "metadata": {},
   "source": [
    "### 4: GloVe embeddings\n",
    "I initially attempted to use Gensim to train Word2Vec embeddings on the dataset. However, due to a persistent ImportError related to the triu function from scipy.linalg, which appears to stem from a deeper compatibility issue between Gensim and my Anaconda environment, I was unable to proceed. Despite attempts to update or reinstall scipy, the problem remained unresolved.\n",
    "\n",
    "As a workaround, I switched to using pre-trained GloVe embeddings from Stanford, which allowed me to compute average word vectors for each tweet without relying on Gensim. This alternative approach provided a robust and widely accepted method for embedding text data, enabling me to proceed with training a classification model effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bb01744-4c80-4175-8934-b898087f00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe Embeddings from File\n",
    "# This function Loads GloVe vectors from a .txt file into a dictionary\n",
    "def load_glove_embeddings(filepath):\n",
    "    embeddings = {}\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "glove = load_glove_embeddings(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c9f131-aed2-47fd-b946-2a2dce9dd12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Tweets to Averaged GloVe Vectors\n",
    "# This function converts a tweet (string) into a fixed-size vector by averaging GloVe vectors of each word in the tweet.\n",
    "def get_glove_avg_vector(text, glove, dim=100):\n",
    "    words = text.split()\n",
    "    vectors = [glove[word] for word in words if word in glove]\n",
    "    if not vectors:\n",
    "        return np.zeros(dim)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Applying vectorization to train and test datasets\n",
    "X_glove = np.vstack(train_df[\"clean_text\"].apply(lambda x: get_glove_avg_vector(x, glove, 100)))\n",
    "X_test_glove = np.vstack(test_df[\"clean_text\"].apply(lambda x: get_glove_avg_vector(x, glove, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49411f5f-d6e5-4dee-a327-ae6638e61aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe Embedding Performance:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       874\n",
      "           1       0.79      0.69      0.74       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.79      0.78      0.78      1523\n",
      "weighted avg       0.79      0.79      0.79      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split and Model Training\n",
    "X_train_g, X_val_g, y_train_g, y_val_g = train_test_split(X_glove, train_df[\"target\"], test_size=0.2, random_state=42)\n",
    "\n",
    "model_glove = LogisticRegression(max_iter=1000)\n",
    "model_glove.fit(X_train_g, y_train_g)\n",
    "\n",
    "y_pred_g = model_glove.predict(X_val_g)\n",
    "print(\"GloVe Embedding Performance:\\n\", classification_report(y_val_g, y_pred_g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e85bc2a-3605-40e2-9416-f70c8d90b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_glove = model_glove.predict(X_test_glove)\n",
    "\n",
    "submission_glove = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': preds_glove\n",
    "})\n",
    "submission_glove.to_csv(\"submission_glove.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad83c6-bb4f-4382-ae28-118bd60123be",
   "metadata": {},
   "source": [
    "### 5: Transformer-Based Model (BERT or RoBERTa)\n",
    "In this section, I used a pre-trained BERT model (bert-base-uncased) from Hugging Face to generate contextualized embeddings for each tweet. First, I loaded the BERT tokenizer and model, set the model to evaluation mode, and moved it to GPU if available. I then defined a function to tokenize each tweet, pass it through BERT, and extract the [CLS] token embedding, which represents the entire sentence. Using this function, I generated dense vector representations for all tweets in the training and test sets. These embeddings were then used as input features for a Logistic Regression model, which was trained on the training portion of the data and evaluated on a validation split. This approach leverages BERTâ€™s ability to capture contextual meaning while keeping the classification pipeline consistent with other models used in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77c461b1-a3c6-4eb8-b2e8-e221624c8bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\disaster-nlp\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the BERT tokenizer (which splits text the way BERT was trained on)\n",
    "# Then using the BERT model to produce embeddings.\n",
    "# model.eval() sets BERT to inference mode (so dropout etc. are disabled).\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "326d81bb-94cb-4530-aecf-118da86b3748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to extract [CLS] token embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "    \n",
    "    return cls_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf615aae-4169-4aed-8688-c2ca903063fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding train texts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7613/7613 [06:36<00:00, 19.20it/s]\n",
      "Embedding test texts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3263/3263 [02:59<00:00, 18.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate BERT embeddings with progress bar\n",
    "X_bert = np.vstack([get_bert_embedding(text) for text in tqdm(train_df[\"text\"].tolist(), desc=\"Embedding train texts\")])\n",
    "X_test_bert = np.vstack([get_bert_embedding(text) for text in tqdm(test_df[\"text\"].tolist(), desc=\"Embedding test texts\")])\n",
    "\n",
    "# Train-test split\n",
    "X_train_b, X_val_b, y_train_b, y_val_b = train_test_split(\n",
    "    X_bert, train_df[\"target\"], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20d3dfe0-8613-4a60-9e86-f2f1d57e90b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Logistic Regression model\n",
    "model_bert = LogisticRegression(max_iter=1000)\n",
    "model_bert.fit(X_train_b, y_train_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8a1d968-e532-4312-9eea-f17bb350724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       874\n",
      "           1       0.79      0.73      0.76       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.80      0.80      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "y_pred_b = model_bert.predict(X_val_b)\n",
    "print(classification_report(y_val_b, y_pred_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "534641d2-c37c-491f-8885-57c7cbaa1618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "preds_bert = model_bert.predict(X_test_bert)\n",
    "\n",
    "# Save submission\n",
    "submission_bert = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'target': preds_bert\n",
    "})\n",
    "submission_bert.to_csv(\"submission_bert.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d5cbb-da71-4091-93a8-e0ef2c478324",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3fe5874-d04f-4192-905f-4c07e27c3230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Representation Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One-Hot Encoding</td>\n",
       "      <td>Sparse Binary</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.7947</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.7934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bag of Words</td>\n",
       "      <td>Count-Based</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.7997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>Weighted Frequency</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.8009</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>0.7959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GloVe Embedding</td>\n",
       "      <td>Dense Embeddings</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>0.7914</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>0.7887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BERT (CLS token)</td>\n",
       "      <td>Contextual Embeddings</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.8043</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>0.8039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model    Representation Type  Accuracy  Precision  Recall  \\\n",
       "0  One-Hot Encoding          Sparse Binary    0.7951     0.7947  0.7951   \n",
       "1      Bag of Words            Count-Based    0.8017     0.8017  0.8017   \n",
       "2            TF-IDF     Weighted Frequency    0.7991     0.8009  0.7991   \n",
       "3   GloVe Embedding       Dense Embeddings    0.7912     0.7914  0.7912   \n",
       "4  BERT (CLS token)  Contextual Embeddings    0.8050     0.8043  0.8050   \n",
       "\n",
       "   F1 Score  \n",
       "0    0.7934  \n",
       "1    0.7997  \n",
       "2    0.7959  \n",
       "3    0.7887  \n",
       "4    0.8039  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_metrics(y_true, y_pred, model_name, rep_type):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Representation Type\": rep_type,\n",
    "        \"Accuracy\": round(report[\"accuracy\"], 4),\n",
    "        \"Precision\": round(report[\"weighted avg\"][\"precision\"], 4),\n",
    "        \"Recall\": round(report[\"weighted avg\"][\"recall\"], 4),\n",
    "        \"F1 Score\": round(report[\"weighted avg\"][\"f1-score\"], 4)\n",
    "    }\n",
    "\n",
    "# Collect metrics from each model\n",
    "results = []\n",
    "\n",
    "results.append(extract_metrics(y_val_onehot, y_pred_onehot, \"One-Hot Encoding\", \"Sparse Binary\"))\n",
    "results.append(extract_metrics(y_val_bow, y_pred_bow, \"Bag of Words\", \"Count-Based\"))\n",
    "results.append(extract_metrics(y_val_tfidf, y_pred_tfidf, \"TF-IDF\", \"Weighted Frequency\"))\n",
    "results.append(extract_metrics(y_val_g, y_pred_g, \"GloVe Embedding\", \"Dense Embeddings\"))\n",
    "results.append(extract_metrics(y_val_b, y_pred_b, \"BERT (CLS token)\", \"Contextual Embeddings\"))\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ea010-d4f2-47f6-b5f0-9d1c6a53270e",
   "metadata": {},
   "source": [
    "Based on the comparison table, I found that all five models achieved relatively similar performance, with BERT (CLS token) slightly outperforming the others in every metric. It achieved the highest accuracy (0.8050) and F1 Score (0.8039), showing the benefit of contextualized embeddings for understanding tweet content.\n",
    "\n",
    "Among the traditional approaches, Bag of Words performed best, with an F1 Score of 0.7997, closely followed by TF-IDF and One-Hot Encoding. Interestingly, despite being a more advanced representation, the GloVe Embedding model underperformed slightly compared to the count-based methods, possibly due to the simplicity of averaging word vectors, which loses context.\n",
    "\n",
    "Overall, this evaluation confirmed that deep contextual embeddings (like those from BERT) offer a measurable improvement, even with a simple logistic regression classifier. However, classical methods like BoW and TF-IDF still remain strong baselines, especially in resource-constrained or interpretable scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41934f6-d189-4686-a146-981620d6976a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
